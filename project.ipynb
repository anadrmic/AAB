{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np, os, sys, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "pd.core.common._random_stat = SEED\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "  \n",
    "  original = loadmat(file) #  dictionary with variable names as keys, and loaded matrices as values\n",
    "  \n",
    "  spk_file = file.replace('.mat', '_spk.mat')\n",
    "  spk = loadmat(spk_file)\n",
    "\n",
    "  ann_file = file.replace('.mat', '_ann.mat')\n",
    "  ann = loadmat(ann_file)\n",
    "\n",
    "  return original, spk, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files_by_pattern(directory, pattern):\n",
    "    \"\"\"\n",
    "    Filter files in a directory based on a specified pattern.\n",
    "\n",
    "    Parameters:\n",
    "    - directory: The directory containing the files.\n",
    "    - pattern: The regular expression pattern to match filenames.\n",
    "\n",
    "    Returns:\n",
    "    - List of filenames matching the pattern.\n",
    "    \"\"\"\n",
    "    files = os.listdir(directory)\n",
    "    filtered_files = [file for file in files if re.match(pattern, file)]\n",
    "    return filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S034_128.mat', 'S024_128.mat', 'S056_128.mat', 'S046_128.mat', 'S091_250.mat', 'S081_250.mat', 'S060_128.mat', 'S012_128.mat', 'S002_128.mat', 'S114_250.mat', 'S104_250.mat', 'S088_250.mat', 'S098_250.mat', 'S061_128.mat', 'S003_128.mat', 'S013_128.mat', 'S105_250.mat', 'S115_250.mat', 'S099_250.mat', 'S089_250.mat', 'S025_128.mat', 'S035_128.mat', 'S080_250.mat', 'S090_250.mat', 'S047_128.mat', 'S057_128.mat', 'S117_250.mat', 'S107_250.mat', 'S011_128.mat', 'S001_128.mat', 'S008_128.mat', 'S018_128.mat', 'S092_250.mat', 'S082_250.mat', 'S055_128.mat', 'S045_128.mat', 'S037_128.mat', 'S027_128.mat', 'S121_250.mat', 'S019_128.mat', 'S009_128.mat', 'S044_128.mat', 'S054_128.mat', 'S083_250.mat', 'S093_250.mat', 'S026_128.mat', 'S036_128.mat', 'S120_250.mat', 'S106_250.mat', 'S116_250.mat', 'S010_128.mat', 'S062_128.mat', 'S048_128.mat', 'S058_128.mat', 'S015_128.mat', 'S005_128.mat', 'S113_250.mat', 'S103_250.mat', 'S051_128.mat', 'S041_128.mat', 'S096_250.mat', 'S086_250.mat', 'S033_128.mat', 'S023_128.mat', 'S087_250.mat', 'S097_250.mat', 'S040_128.mat', 'S050_128.mat', 'S022_128.mat', 'S032_128.mat', 'S059_128.mat', 'S049_128.mat', 'S004_128.mat', 'S014_128.mat', 'S102_250.mat', 'S112_250.mat', 'S030_128.mat', 'S020_128.mat', 'S095_250.mat', 'S085_250.mat', 'S052_128.mat', 'S042_128.mat', 'S109_250.mat', 'S119_250.mat', 'S029_128.mat', 'S039_128.mat', 'S110_250.mat', 'S100_250.mat', 'S016_128.mat', 'S006_128.mat', 'S038_128.mat', 'S028_128.mat', 'S101_250.mat', 'S079_250.mat', 'S111_250.mat', 'S007_128.mat', 'S017_128.mat', 'S021_128.mat', 'S031_128.mat', 'S043_128.mat', 'S053_128.mat', 'S084_250.mat', 'S094_250.mat', 'S118_250.mat', 'S108_250.mat']\n"
     ]
    }
   ],
   "source": [
    "directory = path_to_data  \n",
    "pattern = r'S\\d{3}_\\d{3}\\.mat'  # Regular expression pattern matching 'SXXX_YYY.mat'\n",
    "\n",
    "filtered_files = filter_files_by_pattern(directory, pattern)\n",
    "print(filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = filtered_files[:round(len(filtered_files)*0.8)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S034_128.mat',\n",
       " 'S024_128.mat',\n",
       " 'S056_128.mat',\n",
       " 'S046_128.mat',\n",
       " 'S091_250.mat',\n",
       " 'S081_250.mat',\n",
       " 'S060_128.mat',\n",
       " 'S012_128.mat',\n",
       " 'S002_128.mat',\n",
       " 'S114_250.mat',\n",
       " 'S104_250.mat',\n",
       " 'S088_250.mat',\n",
       " 'S098_250.mat',\n",
       " 'S061_128.mat',\n",
       " 'S003_128.mat',\n",
       " 'S013_128.mat',\n",
       " 'S105_250.mat',\n",
       " 'S115_250.mat',\n",
       " 'S099_250.mat',\n",
       " 'S089_250.mat',\n",
       " 'S025_128.mat',\n",
       " 'S035_128.mat',\n",
       " 'S080_250.mat',\n",
       " 'S090_250.mat',\n",
       " 'S047_128.mat',\n",
       " 'S057_128.mat',\n",
       " 'S117_250.mat',\n",
       " 'S107_250.mat',\n",
       " 'S011_128.mat',\n",
       " 'S001_128.mat',\n",
       " 'S008_128.mat',\n",
       " 'S018_128.mat',\n",
       " 'S092_250.mat',\n",
       " 'S082_250.mat',\n",
       " 'S055_128.mat',\n",
       " 'S045_128.mat',\n",
       " 'S037_128.mat',\n",
       " 'S027_128.mat',\n",
       " 'S121_250.mat',\n",
       " 'S019_128.mat',\n",
       " 'S009_128.mat',\n",
       " 'S044_128.mat',\n",
       " 'S054_128.mat',\n",
       " 'S083_250.mat',\n",
       " 'S093_250.mat',\n",
       " 'S026_128.mat',\n",
       " 'S036_128.mat',\n",
       " 'S120_250.mat',\n",
       " 'S106_250.mat',\n",
       " 'S116_250.mat',\n",
       " 'S010_128.mat',\n",
       " 'S062_128.mat',\n",
       " 'S048_128.mat',\n",
       " 'S058_128.mat',\n",
       " 'S015_128.mat',\n",
       " 'S005_128.mat',\n",
       " 'S113_250.mat',\n",
       " 'S103_250.mat',\n",
       " 'S051_128.mat',\n",
       " 'S041_128.mat',\n",
       " 'S096_250.mat',\n",
       " 'S086_250.mat',\n",
       " 'S033_128.mat',\n",
       " 'S023_128.mat',\n",
       " 'S087_250.mat',\n",
       " 'S097_250.mat',\n",
       " 'S040_128.mat',\n",
       " 'S050_128.mat',\n",
       " 'S022_128.mat',\n",
       " 'S032_128.mat',\n",
       " 'S059_128.mat',\n",
       " 'S049_128.mat',\n",
       " 'S004_128.mat',\n",
       " 'S014_128.mat',\n",
       " 'S102_250.mat',\n",
       " 'S112_250.mat',\n",
       " 'S030_128.mat',\n",
       " 'S020_128.mat',\n",
       " 'S095_250.mat',\n",
       " 'S085_250.mat',\n",
       " 'S052_128.mat',\n",
       " 'S042_128.mat',\n",
       " 'S109_250.mat',\n",
       " 'S119_250.mat']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_files = filtered_files[(round(len(filtered_files)*0.8)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S029_128.mat',\n",
       " 'S039_128.mat',\n",
       " 'S110_250.mat',\n",
       " 'S100_250.mat',\n",
       " 'S016_128.mat',\n",
       " 'S006_128.mat',\n",
       " 'S038_128.mat',\n",
       " 'S028_128.mat',\n",
       " 'S101_250.mat',\n",
       " 'S079_250.mat',\n",
       " 'S111_250.mat',\n",
       " 'S007_128.mat',\n",
       " 'S017_128.mat',\n",
       " 'S021_128.mat',\n",
       " 'S031_128.mat',\n",
       " 'S043_128.mat',\n",
       " 'S053_128.mat',\n",
       " 'S084_250.mat',\n",
       " 'S094_250.mat',\n",
       " 'S118_250.mat',\n",
       " 'S108_250.mat']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "ecg_train = []\n",
    "spk_train = []\n",
    "ann_train = []\n",
    "\n",
    "for file in train_files:\n",
    "  ecg, spk, ann = load_data(path_to_data + '/' + file)\n",
    "  ecg_train.append(ecg)\n",
    "  spk_train.append(spk)\n",
    "  ann_train.append(ann)\n",
    "\n",
    "  train.append(path_to_data + '/' + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = []\n",
    "ecg_validation = []\n",
    "spk_validation = []\n",
    "ann_validation = []\n",
    "\n",
    "for file in validation_files:\n",
    "  \n",
    "  ecg, spk, ann = load_data(path_to_data + '/' + file)\n",
    "  ecg_validation.append(ecg)\n",
    "  spk_validation.append(spk)\n",
    "  ann_validation.append(ann)\n",
    "  \n",
    "  validation.append(path_to_data + '/' + file)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neurokit2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.2.7)\n",
      "Collecting tdqm\n",
      "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neurokit2) (1.26.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neurokit2) (2.1.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neurokit2) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neurokit2) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neurokit2) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tdqm) (4.66.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anadrmic/Library/Python/3.12/lib/python/site-packages (from matplotlib->neurokit2) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->neurokit2) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anadrmic/Library/Python/3.12/lib/python/site-packages (from matplotlib->neurokit2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->neurokit2) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->neurokit2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anadrmic/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\n",
      "Building wheels for collected packages: tdqm\n",
      "  Building wheel for tdqm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1322 sha256=f237875888925ceb27f58e8c0b667c5283dc23c5eeb877b52e6a58a5a42a62eb\n",
      "  Stored in directory: /Users/anadrmic/Library/Caches/pip/wheels/af/02/71/aae0f7ee738abf19498353918ddae0f90a0d6ceb337b0bbc91\n",
      "Successfully built tdqm\n",
      "Installing collected packages: tdqm\n",
      "Successfully installed tdqm-0.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install neurokit2 tdqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(filename):\n",
    "  if '128' in filename:\n",
    "    return 128\n",
    "  else:\n",
    "    return 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
